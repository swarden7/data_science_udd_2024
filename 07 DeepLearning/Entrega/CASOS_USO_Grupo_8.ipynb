{"cells":[{"cell_type":"markdown","metadata":{"id":"if-EnkrnFUvI"},"source":["# __Casos de uso__\n","<font color='red' size=5>Grupo 8.</font>\n","\n","<font color='red'>Módulo: Deep Learning </font>"]},{"cell_type":"markdown","metadata":{"id":"quOGCQUdUcit"},"source":["<font color='red'>__ATENCIÓN:__:<br>\n","Indicamos los caso de uso con el nombre del alumno.</font>\n","\n","# <font color='blue'>**Caso de uso: Alejandro Heredia**</font>\n","\n","#Predicción de Germinación de Semillas con Redes Neuronales Profundas\n","\n","## Problema\n","Actualmente, la empresa realiza pruebas manuales para estimar la tasa de germinación de lotes de semillas, lo cual es costoso y lento. Se busca automatizar la predicción de la tasa de germinación usando datos históricos y ambientales, para optimizar los procesos de selección y distribución.\n","\n","---\n","\n","## Solución Propuesta\n","\n","### Objetivo\n","\n","Desarrollar un modelo de aprendizaje profundo (red neuronal densa) que prediga la tasa de germinación de un lote de semillas a partir de variables como:\n","- Humedad y temperatura durante el almacenamiento\n","- Edad del lote\n","- Tipo de semilla\n","- Resultados de pruebas químicas\n","\n","### Metodología\n","\n","1. **Recolección de datos:**  \n","   - Extraer datos históricos de pruebas de germinación y condiciones de almacenamiento.\n","\n","2. **Preprocesamiento:**  \n","   - Normalizar variables numéricas.\n","   - Codificar variables categóricas (tipo de semilla).\n","\n","3. **Modelado:**  \n","   - Construir una red neuronal simple con capas densas, activación ReLU y una capa de salida lineal.\n","\n","4. **Evaluación:**  \n","   - Dividir datos en entrenamiento y validación.\n","   - Medir el MAE y el R².\n","\n","5. **Despliegue:**  \n","   - Integrar el modelo en una herramienta interna para predicción rápida.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Dr7j-OBHcTDS"},"source":["A continuación un pseudocódigo explicando los pasos\n","\n","```\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","# 1. Preprocesamiento\n","X, y = cargar_datos() # Variables y tasa de germinación\n","X_num, X_cat = separar_numericas_categoricas(X)\n","X_num = StandardScaler().fit_transform(X_num)\n","X_cat = OneHotEncoder().fit_transform(X_cat).toarray()\n","X_pre = np.concatenate([X_num, X_cat], axis=1)\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_pre, y, test_size=0.2)\n","\n","# 2. Modelo\n","model = tf.keras.Sequential([\n","tf.keras.layers.Dense(32, activation='relu', input_shape=(X_pre.shape,)),\n","tf.keras.layers.Dense(16, activation='relu'),\n","tf.keras.layers.Dense(1, activation='linear')\n","])\n","model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n","\n","3. Entrenamiento\n","model.fit(X_train, y_train, epochs=30, batch_size=16, validation_data=(X_val, y_val))\n","\n","4. Evaluación\n","mae, _ = model.evaluate(X_val, y_val)\n","print(f\"MAE en validación: {mae:.2f}\")\n","\n","\n","```\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eqPiVSxGyh6Q"},"source":["# <font color='blue'>**Caso de uso: Fernanda Jahn**</font>\n","## **Clasificación de niveles de espuma en reactores biológicos de PTARs mediante Análisis de Imágenes**\n","\n","**Contexto y problema:**\n","En los reactores biológicos de plantas de tratamiento de aguas residuales (PTARs), la presencia de espuma en la superficie puede ser un indicio de condiciones operacionales inestables. Aunque un cierto nivel de espuma es normal en sistemas biológicos aireados, la acumulación excesiva puede dificultar la transferencia de oxígeno, indicar sobreactivación del lodo o presencia de compuestos no biodegradables, e incluso generar riesgos de sobreflujo o impacto ambiental. Actualmente, la detección de espuma se realiza visualmente por los operadores, lo que limita la frecuencia y objetividad del monitoreo.\n","\n","**Propuesta:**\n","Se propone desarrollar un modelo de clasificación de imágenes basado en redes neuronales convolucionales (CNN), entrenado con un conjunto de imágenes capturadas automáticamente por una cámara fija sobre el reactor (espuma_imagenes). El objetivo es categorizar cada imagen en uno de tres niveles operacionales de presencia de espuma:\n","\n","- **Condición Normal**: sin presencia relevante de espuma.\n","\n","- **Advertencia**: acumulación moderada que podría escalar si no se corrige.\n","\n","- **Crítica**: presencia excesiva que requiere intervención inmediata.\n","\n","Este modelo podrá integrarse a un sistema de alerta o activarse como parte de una lógica de control para ajustar aireación, recirculación o aplicar antiespumantes si fuera necesario.\n","\n","\n","**Explicación de los pasos de desarrollo:**\n","\n","1. **Recolección y preparación de datos**:\n","\n","Dataset espuma_imagenes, con imágenes etiquetadas en las tres clases (normal, advertencia, critico), distribuidas en carpetas o con etiquetas en un DataFrame.\n","\n","2. **Preprocesamiento**:\n","\n","Redimensionamiento de imágenes, normalización de pixeles y división en entrenamiento, validación y test.\n","\n","3. **Arquitectura del modelo**:\n","\n","Red neuronal convolucional simple (como un modelo estilo LeNet o CNN básica con Conv2D → ReLU → MaxPool → FC → Softmax).\n","\n","4. **Entrenamiento**:\n","\n","Con CrossEntropyLoss y optimizador Adam, usando dataloaders con batch training.\n","\n","5. **Evaluación y métricas**:\n","\n","Accuracy, matriz de confusión, precision/recall para las clases."]},{"cell_type":"markdown","metadata":{"id":"2qmKOsLsypNf"},"source":["### <font color='blue'> 1. Pseudocódigo de la Solución"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yc4VJ6yIyrP4"},"outputs":[],"source":["# Paso 1: Cargar dataset\n","dataset = cargar_dataset_de_imagenes('espuma_imagenes', etiquetas=['normal', 'advertencia', 'critico'])\n","\n","# Paso 2: Preprocesamiento\n","imagenes, etiquetas = preprocesar_imagenes(dataset, tamaño=(64,64), normalizar=True)\n","train, val, test = dividir_dataset(imagenes, etiquetas, proporciones=(0.7, 0.2, 0.1))\n","\n","# Paso 3: Crear dataloaders\n","trainloader = crear_dataloader(train, batch_size=32)\n","valloader = crear_dataloader(val, batch_size=32)\n","testloader = crear_dataloader(test, batch_size=32)\n","\n","# Paso 4: Definir red convolucional\n","modelo = RedConvolucional(\n","    conv1=(filtros=8, kernel=3),\n","    conv2=(filtros=16, kernel=3),\n","    fc=(128, 3),  # 3 clases de salida\n","    activacion='relu',\n","    salida='softmax')\n","\n","# Paso 5: Entrenar modelo\n","for epoch in range(num_epochs):\n","    for batch in trainloader:\n","        x, y = batch\n","        y_pred = modelo(x)\n","        loss = cross_entropy(y_pred, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","# Paso 6: Evaluación en set de validación y test\n","evaluar_modelo(modelo, valloader)\n","evaluar_modelo(modelo, testloader)"]},{"cell_type":"markdown","metadata":{"id":"9WAsvHVyy4J9"},"source":["Uno de los principales desafíos en la implementación de este tipo de modelo es su fuerte dependencia de la calidad del set de imágenes. Factores como iluminación variable, condiciones climáticas o el ángulo de la cámara pueden afectar la claridad con que se observa la espuma, impactando directamente la precisión del modelo. A esto se suma la dificultad de la etiquetación, ya que la clasificación entre condiciones “normales”, “moderadas” y “críticas” suele ser subjetiva y dependerá de la experiencia de los operadores humanos. Si el dataset de entrenamiento contiene etiquetas inconsistentes o sesgadas, el modelo aprenderá una clasificación igualmente ambigua.\n","\n","Para abordar estas limitaciones, se podrían considerar estrategias complementarias como:\n","\n","- Aumentar el dataset usando técnicas de data augmentation (rotación, brillo, contraste) para mejorar la robustez del modelo.\n","\n","- Incorporar etiquetado colaborativo, donde varios operadores etiqueten las imágenes y se obtenga una votación o consenso por imagen.\n","\n","- Integrar el modelo con datos contextuales del proceso (como el nivel de aireación, temperatura u OD) para que el sistema no dependa solo de la imagen.\n","\n","- Usar modelos más avanzados, como redes preentrenadas (transfer learning) con redes CNN como ResNet o EfficientNet, que pueden adaptarse mejor con pocos datos etiquetados.\n","\n","Estas mejoras permitirían aumentar la confiabilidad del sistema en operación real, y avanzar hacia una supervisión autónoma más precisa del estado superficial de los reactores."]},{"cell_type":"markdown","metadata":{"id":"YRA6qYNXzVoS"},"source":["# <font color='blue'>**Caso de uso: Gonzalo Barria**</font>\n","## ***Segmentación de Estudiantes de AIEP y Reducción de Dimensionalidad con Autoencoder en PyTorch***\n","\n","El **Instituto Profesional AIEP** es una institución de educación superior con 58 años de experiencia formando profesionales y técnicos de nivel superior para el desarrollo de Chile. Algunas de sus características son que tiene 150.008 metros cuadrados de instalaciones para estudiantes, 96 carreras profesionales y técnicas presenciales y a distancia, 7 Escuelas en distintas áreas del conocimiento, 4.551 docentes insertos en el medio laboral y un 91% empleabilidad promedio de sus titulados.\n","\n","En su administración como **Instituto Profesional AIEP** presenta varios desafíos y dado mi rol como ingeniero de estudios en **AIEP**, podría desarrollar un caso de uso para apoyar a la institución con sus datos académicos y otros indicadores usando Python.\n","\n","**AIEP** enfrenta el desafío de administrar grandes volúmenes de datos relacionados con el rendimiento académico, asistencia y otros indicadores clave de sus estudiantes. Sin un adecuado tratamiento de datos, es difícil identificar tendencias, detectar problemas tempranos como deserción estudiantil y optimizar procesos educativos.\n","\n","Para abordar este desafío, el uso de Python y bibliotecas específicas como NumPy,Pandas, Matplotlib y PyTorch permite una gestión eficiente de los datos, desde su obtención hasta su análisis e incluso su visualización.\n","\n","**Con Deep Learning** podemos ir más allá de modelos clásicos:\n","\n","**Contexto y Problema**\n","\n","El Instituto Profesional AIEP gestiona grandes volúmenes de datos académicos relacionados con el rendimiento estudiantil, asistencia, tasas de aprobación y deserción. Sin herramientas adecuadas de visualización, es difícil comunicar patrones y tendencias de manera clara y persuasiva a tomadores de decisiones.\n","\n","**Datos:** Variables numéricas (calificaciones parciales, asistencia %, participación), secuencias temporales (historial de asistencia), indicadores cualitativos codificados.\n","\n","**Desafío:** Identificar segmentos de estudiantes con alto riesgo de deserción u bajo rendimiento; extraer representaciones latentes que capturen patrones complejos.\n","\n","**Objetivos**\n","\n","**Aprendizaje de Representaciones**\n","\n","Usar un autoencoder profundo para reducir dimensionalidad y extraer un espacio latente que capture correlaciones no lineales.\n","\n","**Segmentación (Clustering)**\n","\n","Agrupar en el espacio latente para descubrir perfiles (e.g. “buenos promedios pero baja asistencia”).\n","\n","**Clasificación Supervisada**\n","\n","Entrenar una MLP (Multilayer Perceptron) sobre las representaciones latentes para predecir la probabilidad de aprobación (aprobado).\n","\n","**Modelado Secuencial**\n","\n","Convoluciones 1D sobre secuencias de asistencia para predecir tendencias de deserción temprana.\n","\n","**Beneficios para AIEP:**\n","\n","**Personalización de estrategias:** Permite diseñar intervenciones específicas para cada segmento.\n","\n","**Optimización de recursos:** Identifica grupos que requieran apoyo académico especial.\n","\n","**Comunicación efectiva:** Visualizaciones claras para facilitar la toma de decisiones en equipos interdisciplinarios.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aO__xSMP8v0N"},"source":["<font color='red'>__ATENCIÓN__: En este caso se utiliza código en python, pero solo como referencia, no es ejecutable en este notebook (produciría un error). EN CASO DE SER EJECUTABLE LOS DATOS SON FICTICIOS Y SOLO SIRVEN COMO REFERENCIA</font>\n","### **Segunda etapa (Desarrollo de código en Python)**\n","\n","**Ejemplos de Código**\n","\n","**1. Autoencoder para Reducción de Dimensionalidad**\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Definición de Autoencoder\n","class Autoencoder(nn.Module):\n","    def __init__(self, input_dim, latent_dim=3):\n","        super().__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, 16), nn.ReLU(),\n","            nn.Linear(16, latent_dim)\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(latent_dim, 16), nn.ReLU(),\n","            nn.Linear(16, input_dim), nn.Sigmoid()\n","        )\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        return self.decoder(z), z\n","\n","# Preparar datos\n","X = torch.tensor(df[['calificacion_parcial','asistencia','participacion']].values, dtype=torch.float32)\n","ds = TensorDataset(X, X)\n","loader = DataLoader(ds, batch_size=32, shuffle=True)\n","\n","# Entrenamiento\n","model_ae = Autoencoder(input_dim=3, latent_dim=2)\n","opt = torch.optim.Adam(model_ae.parameters(), lr=1e-3)\n","loss_fn = nn.MSELoss()\n","\n","for epoch in range(50):\n","    for x_batch, _ in loader:\n","        recon, _ = model_ae(x_batch)\n","        loss = loss_fn(recon, x_batch)\n","        opt.zero_grad(); loss.backward(); opt.step()\n"],"metadata":{"id":"0Pe2sbzcpKBo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Al finalizar, model_ae.encoder proyecta cada estudiante a un espacio latente de dimensión 2."],"metadata":{"id":"5DWV4_oejRH9"}},{"cell_type":"markdown","source":["**2: Clustering en el Espacio Latente**\n","\n"],"metadata":{"id":"C4YRcRUhgIhZ"}},{"cell_type":"code","source":["# Obtener representaciones\n","with torch.no_grad():\n","    Z = model_ae.encoder(X).numpy()\n","\n","from sklearn.cluster import KMeans\n","kmeans = KMeans(n_clusters=3, random_state=42).fit(Z)\n","df['cluster'] = kmeans.labels_\n"],"metadata":{"id":"I3uvqsKHgQ1i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Interpretación:** Cada cluster puede corresponder a “alto rendimiento y alta asistencia”, “bajo rendimiento y baja participación”, etc."],"metadata":{"id":"mpdU7dSNjZgv"}},{"cell_type":"markdown","source":["**3:Clasificación con MLP sobre Latentes**"],"metadata":{"id":"8qo3OcxZpTDU"}},{"cell_type":"code","source":["# Dataset latente + objetivo\n","Z_tensor = torch.tensor(Z, dtype=torch.float32)\n","y_tensor = torch.tensor(df['aprobado'].values, dtype=torch.float32).unsqueeze(1)\n","ds2 = TensorDataset(Z_tensor, y_tensor)\n","loader2 = DataLoader(ds2, batch_size=16, shuffle=True)\n","\n","class MLPClassifier(nn.Module):\n","    def __init__(self, in_dim):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(in_dim, 8), nn.ReLU(),\n","            nn.Dropout(0.3),            # módulo de dropout (Clase 5)\n","            nn.Linear(8, 1), nn.Sigmoid()\n","        )\n","    def forward(self, x):\n","        return self.net(x)\n","\n","model_clf = MLPClassifier(in_dim=2)\n","opt2 = torch.optim.Adam(model_clf.parameters(), lr=1e-3)\n","loss_bce = nn.BCELoss()\n","\n","# Entrenamiento\n","for epoch in range(30):\n","    for z_batch, y_batch in loader2:\n","        y_pred = model_clf(z_batch)\n","        loss = loss_bce(y_pred, y_batch)\n","        opt2.zero_grad(); loss.backward(); opt2.step()\n"],"metadata":{"id":"7l7z5mpNpbBB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Evaluación:** dividir Z_tensor en train/test y calcular accuracy, matriz de confusión, ROC, etc."],"metadata":{"id":"qC3nnDgQjkaR"}},{"cell_type":"markdown","source":["**4. Predicción de Tendencias con Convoluciones 1D**\n","\n","Si disponemos de la serie temporal de asistencia diaria/semanal por estudiante, podemos usar un modelo 1D CNN (módulos DL12):"],"metadata":{"id":"DJB9Q7cPm-bZ"}},{"cell_type":"code","source":["class Conv1DNet(nn.Module):\n","    def __init__(self, seq_len):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv1d(1, 16, kernel_size=3), nn.ReLU(),\n","            nn.MaxPool1d(2),                  # DL10\n","            nn.Conv1d(16, 32, kernel_size=3), nn.ReLU(),\n","            nn.MaxPool1d(2)\n","        )\n","        # calcular salida tras conv+pool según seq_len...\n","        self.fc = nn.Linear(32 * L, 1)      # L = tamaño tras pooling\n","\n","    def forward(self, x):\n","        x = self.conv(x.unsqueeze(1))\n","        x = x.view(x.size(0), -1)\n","        return torch.sigmoid(self.fc(x))\n"],"metadata":{"id":"YG0Fuz1lm-8N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Uso:** entrenar para predecir deserción (0/1) basada en la ventana histórica de asistencia."],"metadata":{"id":"NGJ2ZtD-j5J9"}},{"cell_type":"markdown","source":["**Conclusiones y Aplicaciones**\n","\n","**Representaciones profundas** permiten capturar relaciones no lineales entre variables.\n","\n","**Clusters** en latente revelan perfiles ocultos de estudiantes.\n","\n","**Regularización** con Dropout mejora la generalización del MLP (Clase 5).\n","\n","**Modelos secuenciales (1D CNN)** pueden anticipar deserción a partir de patrones de asistencia, ampliando el análisis más allá del snapshot puntual.\n","\n","**Con esta estrategia, AIEP cuenta con:**\n","\n","Diagnóstico avanzado de riesgo académico.\n","\n","Intervenciones personalizadas según segmentos descubiertos.\n","\n","Predicciones tempranas de deserción para optimizar recursos de acompañamiento.\n","\n","\n"],"metadata":{"id":"U_rm-vmUqvlt"}},{"cell_type":"markdown","metadata":{"id":"KTbRHzK_KvBn"},"source":["# <font color='blue'>**Caso de uso: Rodrigo Fuenzalida**</font>\n","\n","Aquí tienes un caso de uso más sencillo con deep learning, manteniendo la temática dental pero reducido en complejidad y tamaño:\n","\n","\n","### Caso de Uso: Detección de Caries en Radiografías Dentales (Deep Learning - Clasificación Binaria)\n","\n","#### 1. Introducción\n","**Objetivo**:  \n","Crear un modelo de deep learning que clasifique automáticamente radiografías dentales en \"Caries\" (1) o \"Sin Caries\" (0), para asistir a odontólogos en diagnósticos rápidos.\n","\n","**Dataset**:  \n","- 1000 imágenes de radiografías etiquetadas (500 con caries, 500 sin caries).\n","- Tamaño de imagen: 224x224 píxeles (RGB).\n","\n","#### 2. Pseudocódigo\n","\n","```python\n","# 1. Cargar y preprocesar datos\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Generadores de datos con aumento para entrenamiento\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    zoom_range=0.2,\n","    validation_split=0.2  # 80% entrenamiento, 20% validación\n",")\n","\n","train_data = train_datagen.flow_from_directory(\n","    'ruta_imagenes/',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='training'\n",")\n","\n","val_data = train_datagen.flow_from_directory(\n","    'ruta_imagenes/',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='binary',\n","    subset='validation'\n",")\n","\n","# 2. Construir modelo CNN simple\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","# 3. Compilar y entrenar\n","model.compile(\n","    optimizer='adam',\n","    loss='binary_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","history = model.fit(\n","    train_data,\n","    validation_data=val_data,\n","    epochs=10\n",")\n","\n","# 4. Evaluar\n","test_loss, test_acc = model.evaluate(val_data)\n","print(f'Precisión en validación: {test_acc:.2f}')\n","\n","# 5. Guardar modelo para uso clínico\n","model.save('modelo_deteccion_caries.h5')\n","```\n","\n","#### 3. Salida Esperada\n","```\n","Found 800 images belonging to 2 classes.\n","Found 200 images belonging to 2 classes.\n","Epoch 1/10\n","25/25 [==============================] - 30s 1s/step - loss: 0.6928 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n","...\n","Epoch 10/10\n","25/25 [==============================] - 28s 1s/step - loss: 0.3012 - accuracy: 0.8875 - val_loss: 0.3500 - val_accuracy: 0.8500\n","Precisión en validación: 0.85\n","```\n","\n","\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"X52aXwyncyjC"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1mXdwdbZKpzAzgrs_n5yYuEzHQGrYV6Hn","timestamp":1638315867583}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}