{"cells":[{"cell_type":"markdown","metadata":{"id":"if-EnkrnFUvI"},"source":["# __Casos de uso__\n","<font color='red' size=5>Grupo 8.</font>\n","\n","<font color='red'>Módulo: Aprendizaje Supervisado </font>"]},{"cell_type":"markdown","metadata":{"id":"quOGCQUdUcit"},"source":["<font color='red'>__ATENCIÓN:__:<br>\n","Indicamos los caso de uso con el nombre del alumno.</font>\n","\n","# <font color='blue'>**Caso de uso: Alejandro Heredia**</font>\n","\n","## Predicción de Rendimiento de Cultivos en una Empresa Semillera\n","Problema:\n","Nuestra empresa multinacional semillera enfrenta el desafío de predecir el rendimiento de diferentes variedades de cultivos en diversas condiciones climáticas y geográficas. Esto es crucial para optimizar la producción, reducir costos y mejorar la calidad de los productos. Actualmente, las decisiones se basan en experiencia y datos históricos, pero utilizando el conocimiento visto en este módulo podríamos implementar un sistema más preciso y escalable.\n","\n","###Metodología:\n","####- Recolección de Datos:\n","\n","Recopilar datos históricos de rendimiento de cultivos, incluyendo variables como tipo de semilla, condiciones climáticas (temperatura, precipitación), tipo de suelo, prácticas agrícolas y ubicación geográfica.\n","\n","####- Preprocesamiento de Datos:\n","\n","Limpiar y normalizar los datos para eliminar valores faltantes y outliers.\n","\n","Transformar variables categóricas en numéricas si es necesario.\n","\n","####- Selección del Modelo:\n","\n","Utilizar algoritmos de aprendizaje supervisado como Regresión Lineal, Random Forest o Gradient Boosting para predecir el rendimiento de los cultivos.\n","\n","####- Entrenamiento y Validación del Modelo:\n","\n","Dividir los datos en conjuntos de entrenamiento y validación.\n","\n","Entrenar el modelo con el conjunto de entrenamiento y evaluar su rendimiento con el conjunto de validación.\n","\n","####- Implementación y Monitoreo:\n","\n","Implementar el modelo en un sistema que permita la predicción continua del rendimiento de cultivos.\n","\n","Monitorear el desempeño del modelo y ajustarlo según sea necesario."]},{"cell_type":"markdown","metadata":{"id":"Dr7j-OBHcTDS"},"source":["A continuación un pseudocódigo explicando los pasos\n","\n","```\n","# Paso 1: Importar librerías y cargar datos\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","df = pd.read_csv('datos_cultivos.csv')\n","\n","# Paso 2: Preprocesamiento de datos\n","df = df.dropna()  # Eliminar filas con valores faltantes\n","df['tipo_semilla'] = pd.Categorical(df['tipo_semilla']).codes  # Transformar categóricas\n","\n","# Paso 3: Dividir datos en entrenamiento y validación\n","X = df.drop('rendimiento', axis=1)  # Variables predictoras\n","y = df['rendimiento']  # Variable objetivo\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Paso 4: Entrenar modelo\n","modelo = RandomForestRegressor(n_estimators=100, random_state=42)\n","modelo.fit(X_train, y_train)\n","\n","# Paso 5: Evaluar modelo\n","y_pred = modelo.predict(X_test)\n","mse = mean_squared_error(y_test, y_pred)\n","print(f\"Error cuadrático medio: {mse:.2f}\")\n","\n","# Paso 6: Implementar modelo para predicciones futuras\n","def predecir_rendimiento(datos_nuevos):\n","    return modelo.predict(datos_nuevos)\n","\n","# Ejemplo de uso\n","datos_nuevos = pd.DataFrame({\n","    'tipo_semilla': [1],\n","    'temperatura': [25],\n","    'precipitacion': [100],\n","    'tipo_suelo': [2]\n","})\n","rendimiento_predicho = predecir_rendimiento(datos_nuevos)\n","print(f\"Rendimiento predicho: {rendimiento_predicho[0]:.2f}\")\n","\n","```\n","\n","\n"]},{"cell_type":"markdown","source":["Este pseudocódigo resume los pasos clave para desarrollar un sistema de predicción de rendimiento de cultivos utilizando aprendizaje supervisado."],"metadata":{"id":"mhDywjCwoOOw"}},{"cell_type":"markdown","metadata":{"id":"eqPiVSxGyh6Q"},"source":["# <font color='blue'>**Caso de uso: Fernanda Jahn**</font>\n","## **Estimación del Oxígeno Disuelto en Reactores Biológicos usando Modelos de Aprendizaje Supervisado (Soft-Sensor)**\n","\n","En el caso de uso anterior, se agruparon días con condiciones operacionales similares en los reactores biológicos de la PTAR, para analizar cómo estas condiciones se relacionaban con el consumo energético. Como siguiente paso, se propone construir un soft-sensor de oxígeno disuelto (OD), que permita estimar esta variable a partir de otras que sí se miden de forma confiable y continua en la planta.\n","\n","Esto es útil porque en la operación real, los sensores de OD en línea suelen ensuciarse, perder precisión o incluso dejar de funcionar por períodos largos. Un soft-sensor es básicamente un modelo que, usando otras variables del proceso, permite estimar cuánto OD hay en el reactor, sin depender exclusivamente del sensor físico.\n","\n","Para entrenar este modelo, se usarían variables como flujo de aire, SST en el reactor, SST en la recirculación, pH, conductividad, temperatura del agua y el % de apertura de válvula de aire o tiempo de aireación. La idea es que el modelo aprenda la relación entre estas variables y el OD medido manualmente cada dos horas, y luego pueda predecir OD en todo momento.\n","\n","Tener este tipo de estimación no solo permite validar si el sensor físico está entregando valores razonables, sino que también abre la puerta a automatizar los ciclos on/off de los aireadores o optimizar las consignas de oxígeno de forma más robusta y flexible.\n","\n","\n","**Explicación de los pasos de desarrollo:**\n","\n","1. Preparación de los datos históricos y filtrado de periodos confiables.\n","\n","2. Análisis exploratorio para ver cómo se relaciona el OD con las otras variables.\n","\n","3. División del dataset en entrenamiento y prueba.\n","\n","4. Entrenamiento de distintos modelos supervisados (como regresión lineal, árboles y random forest).\n","\n","5. Validación cruzada para verificar estabilidad del modelo.\n","\n","6. Visualización de resultados: comparar OD real vs estimado.\n","\n","7. Conclusiones: ver si el modelo es confiable como respaldo y si se puede aplicar en la operación."]},{"cell_type":"markdown","metadata":{"id":"2qmKOsLsypNf"},"source":["### <font color='blue'> 1. Pseudocódigo de la Solución"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yc4VJ6yIyrP4"},"outputs":[],"source":["# 1. Cargar datos de OD manual (cada 2 horas) y variables online\n","od_manual = cargar_datos_od_manual()\n","datos_online = cargar_datos_operacionales()\n","\n","# 2. Alinear formatos de fecha/hora\n","od_manual['timestamp'] = pd.to_datetime(od_manual['timestamp'])\n","datos_online['timestamp'] = pd.to_datetime(datos_online['timestamp'])\n","\n","# 3. Re-samplear datos online para coincidir con frecuencia de OD\n","datos_online_2h = datos_online.resample('2H', on='timestamp').mean()\n","\n","# 4. Unir ambos datasets por timestamp\n","df = pd.merge_asof(od_manual.sort_values('timestamp'),\n","                   datos_online_2h.sort_values('timestamp'),\n","                   on='timestamp')\n","\n","# 5. Limpieza\n","df = df.dropna()  # Eliminar valores nulos\n","df = eliminar_outliers(df)\n","\n","# 6. Selección de variables\n","X = df[['flujo_aire', 'sst_reactor', 'sst_recirculacion',\n","        'ph', 'conductividad', 'temperatura', 'tiempo_aireacion']]\n","y = df['od']\n","\n","# 7. División en entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 8. Comparar modelos base\n","modelos = [LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor()]\n","comparar_modelos(modelos, X_train, y_train, X_test, y_test)\n","\n","# 9. Optimización con GridSearchCV\n","param_grid = {\n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [5, 10, 20, None]\n","}\n","grid_rf = GridSearchCV(RandomForestRegressor(), param_grid, scoring='neg_mean_squared_error', cv=5)\n","grid_rf.fit(X_train, y_train)\n","mejor_modelo = grid_rf.best_estimator_\n","\n","# 10. Validación cruzada (5 folds)\n","cv_scores = cross_val_score(mejor_modelo, X_train, y_train, scoring='r2', cv=5)\n","\n","# 11. Predicción y evaluación\n","y_pred = mejor_modelo.predict(X_test)\n","\n","# 12. Calcular métricas\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test, y_pred)\n","\n","# 13. Visualización de desempeño\n","graficar_real_vs_estimado(y_test, y_pred)\n","graficar_errores(y_test, y_pred)  # residuos\n","\n","# 14. Análisis de residuos\n","sns.histplot(y_test - y_pred, kde=True)\n","plt.title(\"Distribución de los residuos\")\n","plt.xlabel(\"Error (OD real - OD estimado)\")\n","plt.axvline(0, color='red', linestyle='--')"]},{"cell_type":"markdown","metadata":{"id":"9WAsvHVyy4J9"},"source":["Un desafío para este tipo de aplicaciones es que muchas veces los datos no están registrados a la misma frecuencia o con la misma calidad. Por ejemplo, el OD manual suele tener menos puntos que las variables en línea, y eso hace que haya que adaptar bien los datos antes de entrenar cualquier modelo. También es común que haya ruido, outliers o vacíos en los registros, lo que puede afectar el desempeño si no se limpian bien.\n","\n","Otra cosa importante es que estos modelos tienen que ser evaluados más allá del R² o el RMSE. Revisar los residuos, ver cuándo y cómo se equivoca, y validar con diferentes cortes de datos (train/test) ayuda a saber si realmente se puede usar en operación.\n","\n","A futuro, se podría avanzar hacia modelos que consideren cómo cambian las condiciones con el tiempo, o incorporar este tipo de estimaciones en sistemas de control automático. Eso permitiría pasar de un análisis puntual a una herramienta que apoye decisiones en tiempo real dentro de la planta."]},{"cell_type":"markdown","metadata":{"id":"YRA6qYNXzVoS"},"source":["# <font color='blue'>**Caso de uso: Gonzalo Barria**</font>\n","## ***Segmentación de Estudiantes y Reducción de Dimensionalidad aplicada a los Datos Académicos de AIEP usando Aprendizaje Supervisado***\n","\n","El **Instituto Profesional AIEP** es una institución de educación superior con 58 años de experiencia formando profesionales y técnicos de nivel superior para el desarrollo de Chile. Algunas de sus características son que tiene 150.008 metros cuadrados de instalaciones para estudiantes, 96 carreras profesionales y técnicas presenciales y a distancia, 7 Escuelas en distintas áreas del conocimiento, 4.551 docentes insertos en el medio laboral y un 91% empleabilidad promedio de sus titulados.\n","\n","En su administración como **Instituto Profesional AIEP** presenta varios desafíos y dado mi rol como ingeniero de estudios en **AIEP**, podría desarrollar un caso de uso apoyar a la institución con sus datos académicos y otros indicadores usando Python, especificamente la librería de visualización Seaborn y también Numpy para datos.\n","\n","AIEP enfrenta el desafío de administrar grandes volúmenes de datos relacionados con el rendimiento académico, asistencia y otros indicadores clave de sus estudiantes. Sin un adecuado tratamiento de datos, es difícil identificar tendencias, detectar problemas tempranos como deserción estudiantil y optimizar procesos educativos.\n","\n","Para abordar este desafío, el uso de Python y bibliotecas específicas como NumPy,Pandas, Matplotlib o Seaborn permite una gestión eficiente de los datos, desde su obtención hasta su análisis e incluso su visualización.\n","\n","**Contexto y Problema**\n","\n","El Instituto Profesional AIEP gestiona grandes volúmenes de datos académicos relacionados con el rendimiento estudiantil, asistencia, tasas de aprobación y deserción. Sin herramientas adecuadas de visualización, es difícil comunicar patrones y tendencias de manera clara y persuasiva a tomadores de decisiones.\n","\n","**Objetivos**\n","\n","Predecir el rendimiento académico de los estudiantes (o su probabilidad de aprobar) utilizando variables como calificaciones parciales, asistencia, participación, entre otras. De esta forma, se podrán identificar factores determinantes del éxito académico y diseñar estrategias de intervención.\n","\n","Ejemplo de pregunta a responder:\n","\n","¿Cómo influye la asistencia, la participación y las calificaciones parciales en la probabilidad de aprobación?\n","\n","¿Cuál es el rendimiento esperado de un estudiante dado su perfil?\n","\n","\n","**Beneficios para AIEP:**\n","\n","**Personalización de estrategias:** Permite diseñar intervenciones específicas para cada segmento.\n","\n","**Optimización de recursos:** Identifica grupos que requieran apoyo académico especial.\n","\n","**Comunicación efectiva:** Visualizaciones claras para facilitar la toma de decisiones en equipos interdisciplinarios.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aO__xSMP8v0N"},"source":["<font color='red'>__ATENCIÓN__: En este caso se utiliza código en python, pero solo como referencia, no es ejecutable en este notebook (produciría un error). EN CASO DE SER EJECUTABLE LOS DATOS SON FICTICIOS Y SOLO SIRVEN COMO REFERENCIA</font>\n","### **Segunda etapa (Desarrollo de código en Python)**\n","\n","**Ejemplos de Código**\n","\n","**Paso 1: Proceso de Desarrollo del Modelo Supervisado**\n","\n","**Preparación de los Datos**\n","\n","Se parte de un DataFrame que contiene variables predictoras y una variable objetivo. Por ejemplo, podríamos definir una variable \"aprobado\" (0 = no, 1 = sí) basada en un umbral de calificación.\n","\n","\n","\n"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Simulación de datos:\n","np.random.seed(42)\n","df = pd.DataFrame({\n","    'calificacion_parcial': np.random.normal(5, 1, 200),\n","    'asistencia': np.random.uniform(70, 100, 200),\n","    'participacion': np.random.uniform(1, 10, 200)\n","})\n","\n","# Creación de la variable objetivo (aprobado: 1 si calificacion_parcial >= 5, sino 0)\n","df['aprobado'] = (df['calificacion_parcial'] >= 5).astype(int)\n","\n","# Visualización de las primeras filas\n","print(df.head())\n"],"metadata":{"id":"0Pe2sbzcpKBo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Paso 2: División del Dataset**\n","\n","Antes de entrenar un modelo supervisado, es esencial dividir los datos en conjuntos de entrenamiento y prueba para evaluar el rendimiento del modelo.\n","\n"],"metadata":{"id":"C4YRcRUhgIhZ"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Variables predictoras y variable objetivo\n","X = df[['calificacion_parcial', 'asistencia', 'participacion']]\n","y = df['aprobado']\n","\n","# División de los datos (70% entrenamiento, 30% prueba)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"],"metadata":{"id":"I3uvqsKHgQ1i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Paso 3:Modelado Supervisado**\n","\n","Puedes experimentar con diferentes algoritmos de clasificación. A continuación, se muestran ejemplos con regresión logística, k-NN y Random Forest.\n","\n","**a) Regresión Logística**"],"metadata":{"id":"8qo3OcxZpTDU"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","# Entrenar el modelo\n","modelo_log = LogisticRegression()\n","modelo_log.fit(X_train, y_train)\n","\n","# Predicciones y evaluación\n","y_pred_log = modelo_log.predict(X_test)\n","print(\"Exactitud Regresión Logística:\", accuracy_score(y_test, y_pred_log))\n","print(\"Matriz de confusión:\", confusion_matrix(y_test, y_pred_log))\n"],"metadata":{"id":"7l7z5mpNpbBB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**b) k-Nearest Neighbors (k-NN)**"],"metadata":{"id":"DJB9Q7cPm-bZ"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","# Entrenar el modelo k-NN (con k=5, por ejemplo)\n","modelo_knn = KNeighborsClassifier(n_neighbors=5)\n","modelo_knn.fit(X_train, y_train)\n","\n","# Predicciones y evaluación\n","y_pred_knn = modelo_knn.predict(X_test)\n","print(\"Exactitud k-NN:\", accuracy_score(y_test, y_pred_knn))\n"],"metadata":{"id":"YG0Fuz1lm-8N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**c) Random Forest**"],"metadata":{"id":"H4eqjNa2nD67"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","# Entrenar el modelo Random Forest\n","modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","modelo_rf.fit(X_train, y_train)\n","\n","# Predicciones y evaluación\n","y_pred_rf = modelo_rf.predict(X_test)\n","print(\"Exactitud Random Forest:\", accuracy_score(y_test, y_pred_rf))\n"],"metadata":{"id":"xbi8ynJsnEO6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**4. Interpretación de Resultados y Validación**\n","\n","Después de entrenar los modelos, se deben analizar las métricas de evaluación (exactitud, matriz de confusión, curvas ROC, etc.) para seleccionar el modelo que mejor se adapte al problema. También se puede usar validación cruzada para asegurar la robustez del modelo."],"metadata":{"id":"-zfR5AwQnNvb"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","\n","# Ejemplo de validación cruzada para el modelo de Random Forest\n","cv_scores = cross_val_score(modelo_rf, X, y, cv=5)\n","print(\"Puntuaciones de validación cruzada:\", cv_scores)\n","print(\"Puntuación media:\", np.mean(cv_scores))\n"],"metadata":{"id":"xnkw62RfnPiL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Conclusiones y Aplicaciones**\n","\n","**Personalización y toma de decisiones:**\n","\n","Al predecir la probabilidad de aprobación de un estudiante, la institución puede identificar a aquellos que requieran intervenciones tempranas o refuerzos académicos.\n","\n","**Optimización de recursos:**\n","\n","Permite enfocar esfuerzos y recursos en grupos de estudiantes con mayor riesgo de no aprobar, incrementando la eficiencia de las estrategias educativas.\n","\n","**Estrategias de mejora continua:**\n","\n","A partir de los modelos supervisados se pueden simular distintos escenarios y evaluar el impacto de cambios en políticas de asistencia, metodología de enseñanza, entre otros.\n","\n","Este enfoque supervisado se adapta a los temas vistos en clase (como regresión, k-NN, SVM, Random Forest, etc.), permitiendo utilizar las herramientas y técnicas aprendidas para abordar problemas reales en el ámbito académico.\n","\n"],"metadata":{"id":"U_rm-vmUqvlt"}},{"cell_type":"markdown","metadata":{"id":"KTbRHzK_KvBn"},"source":["# <font color='blue'>**Caso de uso: Rodrigo Fuenzalida**</font>\n","\n","Caso de Uso: Clasificación de Necesidad de Atención Dental Urgente en Niños\n","(Aprendizaje Supervisado - Clasificación Binaria)\n","\n","### 1. Introducción\n","\n","En el marco del Programa CERO, se busca optimizar la asignación de recursos en clínicas dentales públicas mediante un modelo de aprendizaje supervisado que prediga si un niño requiere atención dental urgente (ej. dolor agudo, infección) basado en su historial de caries, hábitos de higiene y datos demográficos.\n","\n","#### Objetivos:\n","Predecir urgencias dentales para priorizar citas.\n","\n","Reducir tiempos de espera en casos críticos.\n","\n","Identificar factores de riesgo asociados (ej. migración, falta de prevención).\n","\n","### 2. Datos y Variables\n","Dataset:\n","Registros de niños 0-9 años atendidos en el programa.\n","\n","Variable objetivo binaria:\n","\n","URGENCIA_DENTAL (0 = No urgente, 1 = Urgente).\n","\n","#### Variables predictoras:\n","\n","* DAÑO_POR_CARIES\tNumérica\tÍndice de caries (0-10).\n","* RIESGO_CARIOGENICO\tCategórica\tAlto/Bajo.\n","* ESTADO_MIGRATORIO\tCategórica\tMigrante/No migrante.\n","* FRECUENCIA_CEPILLADO\tNumérica\tVeces por día (0-3).\n","* DOLOR_RECIENTE\tBinaria\t1 = Sí, 0 = No (últimos 3 meses).\n","\n","### 3. Pseudocódigo\n","#### 3.1. Preprocesamiento\n","```\n","# Cargar datos  \n","df = cargar_csv('datos_niños_dentales.csv')  \n","\n","# Convertir variables categóricas  \n","df['RIESGO_CARIOGENICO'] = df['RIESGO_CARIOGENICO'].map({'bajo': 0, 'alto': 1})  \n","df['ESTADO_MIGRATORIO'] = df['ESTADO_MIGRATORIO'].map({'no migrante': 0, 'migrante': 1})  \n","\n","# Normalizar variables numéricas  \n","from sklearn.preprocessing import StandardScaler  \n","scaler = StandardScaler()  \n","df[['DAÑO_POR_CARIES', 'FRECUENCIA_CEPILLADO']] = scaler.fit_transform(df[['DAÑO_POR_CARIES', 'FRECUENCIA_CEPILLADO']])  \n","\n","# Dividir datos en entrenamiento y prueba\n","from sklearn.model_selection import train_test_split  \n","\n","# Definir variables predictoras (X) y variable objetivo (y)  \n","X = df[['DAÑO_POR_CARIES', 'RIESGO_CARIOGENICO', 'ESTADO_MIGRATORIO', 'FRECUENCIA_CEPILLADO', 'DOLOR_RECIENTE']]  \n","y = df['URGENCIA_DENTAL']  # Variable objetivo binaria  \n","\n","# Dividir en 70% entrenamiento y 30% prueba (estratificado para mantener proporción de clases)  \n","X_train, X_test, y_train, y_test = train_test_split(  \n","    X, y,  \n","    test_size=0.3,  \n","    random_state=42,  # Semilla para reproducibilidad  \n","    stratify=y       # Balancear clases en ambos conjuntos  \n",")  \n","\n","\n","\n","```\n","\n","### 4. Modelado y Evaluación\n","#### 4.1. Entrenamiento de Múltiples Modelos\n","Compararemos 3 algoritmos de clasificación:\n","\n","```\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier  \n","from sklearn.linear_model import LogisticRegression  \n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score  \n","\n","# Modelos a evaluar  \n","modelos = {  \n","    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),  \n","    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, random_state=42),  \n","    \"Regresión Logística\": LogisticRegression(max_iter=1000, random_state=42)  \n","}  \n","\n","# Entrenar y evaluar cada modelo  \n","resultados = {}  \n","for nombre, modelo in modelos.items():  \n","    modelo.fit(X_train, y_train)  \n","    y_pred = modelo.predict(X_test)  \n","    resultados[nombre] = {  \n","        \"Accuracy\": accuracy_score(y_test, y_pred),  \n","        \"F1-Score\": f1_score(y_test, y_pred),  \n","        \"ROC-AUC\": roc_auc_score(y_test, y_pred)  \n","    }  \n","\n","# Mostrar resultados  \n","import pandas as pd  \n","pd.DataFrame(resultados).T.round(2)  \n","Salida esperada:\n","\n","Modelo\tAccuracy\tF1-Score\tROC-AUC\n","Random Forest\t0.87\t0.85\t0.89\n","Gradient Boosting\t0.86\t0.84\t0.88\n","Regresión Logística\t0.82\t0.80\t0.83\n","\n","```\n","\n","#### 4.2. Optimización de Hiperparámetros\n","Usaremos GridSearchCV en el mejor modelo (Random Forest):\n","\n","```\n","from sklearn.model_selection import GridSearchCV  \n","\n","# Definir parámetros a optimizar  \n","param_grid = {  \n","    'n_estimators': [50, 100, 200],  \n","    'max_depth': [3, 5, 7],  \n","    'min_samples_split': [2, 5]  \n","}  \n","\n","# Búsqueda de mejores parámetros  \n","grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='f1')  \n","grid_search.fit(X_train, y_train)  \n","\n","# Mejor modelo  \n","mejor_modelo = grid_search.best_estimator_  \n","print(f\"Mejores parámetros: {grid_search.best_params_}\")  \n","Salida:\n","\n","\n","Mejores parámetros: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 200}  \n","```\n","\n","#### 4.3. Evaluación del Modelo Optimizado\n","\n","```\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  \n","\n","# Predecir con el modelo optimizado  \n","y_pred_opt = mejor_modelo.predict(X_test)  \n","\n","# Matriz de confusión  \n","cm = confusion_matrix(y_test, y_pred_opt)  \n","ConfusionMatrixDisplay(cm, display_labels=[\"No Urgente\", \"Urgente\"]).plot(cmap='Blues')  \n","plt.title(\"Matriz de Confusión (Modelo Optimizado)\")  \n","plt.show()  \n","\n","# Reporte de clasificación  \n","print(classification_report(y_test, y_pred_opt))  \n","Salida:\n","\n","Precision\tRecall\tF1-Score\tSupport\n","No Urgente\t0.88\t0.92\t0.90\t150\n","Urgente\t0.89\t0.83\t0.86\t120\n","```\n","#### 4.4. Visualización de Resultados\n","\n","Curva ROC\n","```\n","from sklearn.metrics import RocCurveDisplay  \n","\n","RocCurveDisplay.from_estimator(mejor_modelo, X_test, y_test)  \n","plt.plot([0, 1], [0, 1], linestyle='--', color='red')  \n","plt.title(\"Curva ROC\")  \n","plt.show()  \n","```\n","Importancia de Características\n","\n","```\n","importancias = mejor_modelo.feature_importances_  \n","pd.Series(importancias, index=X.columns).sort_values().plot(kind='barh')  \n","plt.title(\"Importancia de Variables\")  \n","plt.show()  \n","```\n","#### Interpretación:\n","\n","Variables más importantes: DAÑO_POR_CARIES y DOLOR_RECIENTE.\n","\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"X52aXwyncyjC"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1mXdwdbZKpzAzgrs_n5yYuEzHQGrYV6Hn","timestamp":1638315867583}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}